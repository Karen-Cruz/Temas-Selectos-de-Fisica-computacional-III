{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "    \n",
    "# <center>Clase 8. Noviembre 18 del 2020 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Classification Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Classification predictive modeling is the task of approximating a mapping function F from input variables (X) to <font color='red' > $\\bf discrete$ <font color='black' > target variables (y). In statistics a variable that can take on one of a limited number of possible values is called a $\\bf categorical$ $\\bf variable$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Regression Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "Regression predictive modeling is the task of approximating a mapping function F from input variables (X) to a <font color='red' > $\\bf continuos$ <font color='black' > target variable (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "A classification problem requires that samples be classified into one of two or more classes.\n",
    "\n",
    "A classification can have real-valued or discrete input variables.\n",
    "\n",
    "A problem with two classes is often called a two-class or binary classification problem.\n",
    "\n",
    "A problem with more than two classes is often called a multi-class classification problem.\n",
    "\n",
    "A problem where a sample is assigned multiple classes is called a multi-label classification problem.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T17:16:20.479536Z",
     "start_time": "2020-11-16T17:16:20.470759Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Handwritten Digits Classification using MNIST database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "[Hand written Zip code recognition](./clase8/Back-propag-hand-written-cnn-lecun-1989.pdf)\n",
    "\n",
    "\n",
    "<img src='mnist.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:05.966969Z",
     "start_time": "2020-11-17T21:24:04.476726Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T17:41:15.942872Z",
     "start_time": "2020-11-16T17:41:15.933507Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <font size=4 color='black'>   \n",
    "The database mnist can be downloaded from the following URL: \n",
    "    \n",
    "[MNIST data download](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "The data to train and test the neuronal network are in the file 'mnist.pkl.gz'.\n",
    "\n",
    "    gzip.open('filename', mode='rb') open the compressed binary file 'filename'.\n",
    "    \n",
    "   The documentation of gzip.open can be found at [gzip.open(...)](https://docs.python.org/3/library/gzip.html#gzip.open)\n",
    "\n",
    "    pickle.load('file', encoding = 'latin1') decode the file 'file' in latin1\n",
    "\n",
    "Documentation: [pickle.load(...)](https://docs.python.org/3/library/pickle.html#pickle.load)\n",
    "\n",
    "The function 'load_data()' has three data sets as output: \n",
    "\n",
    "    train_data  # Data for training\n",
    "    val_data    # Data for validation\n",
    "    test_data   # Data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:05.972096Z",
     "start_time": "2020-11-17T21:24:05.968383Z"
    }
   },
   "outputs": [],
   "source": [
    "# The database is in the working directory: mnist.pkl.gz file.\n",
    "    \n",
    "def load_data():\n",
    "\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    \n",
    "    train_data, val_data, test_data = pickle.load(f, encoding=\"latin1\")\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return (train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.792093Z",
     "start_time": "2020-11-17T21:24:05.974070Z"
    }
   },
   "outputs": [],
   "source": [
    "# the data are loaded in three sets: train_data, val_data and test_data \n",
    "\n",
    "train_data, val_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "Each of these sets is a tuple with two entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.798287Z",
     "start_time": "2020-11-17T21:24:06.793584Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The type of train_data: \", type(train_data), \"with length: \", len(train_data) )\n",
    "print(\"The type of val_data: \", type(val_data), \"with length: \", len(val_data) )\n",
    "print(\"The type of test_data: \", type(test_data), \"with length: \", len(test_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.810520Z",
     "start_time": "2020-11-17T21:24:06.799891Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Shape of the first element of the train_data tuple: \", train_data[0].shape)\n",
    "print(\"Shape of the second element of the train_data tuple: \", train_data[1].shape)\n",
    "print(\"Shape of the first element of the val_data tuple: \", val_data[0].shape)\n",
    "print(\"Shape of the second element of the val_data tuple: \", val_data[1].shape)\n",
    "print(\"Shape of the first element of the test_data tuple: \", test_data[0].shape)\n",
    "print(\"Shape of the second element of the test_data tuple: \", test_data[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T16:53:44.374743Z",
     "start_time": "2020-03-24T16:53:44.366238Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Analyzing the data extracted from MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "The first entry corresponds to the network inputs (the features of the images) and the second entry corresponds to the targets (the corresponding digits associated to the images). It is to note that pixel values were rescaled to values between 0.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.822702Z",
     "start_time": "2020-11-17T21:24:06.811843Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"features 150 to 199 of the first training sample \\n \\n\", train_data[0][0][150:200])\n",
    "print(\"\\n y value of the first training sample =\",train_data[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:18:56.606700Z",
     "start_time": "2020-03-24T20:18:56.598151Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "    \n",
    "Viewing one sample from the data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "The digits in the MNIST dataset are images of 28x28 pixels. \n",
    "    \n",
    "In the recovered datasets, images were represented by vectors of dimension 28x28=784. \n",
    "    \n",
    "To deploy the digit image of a sample (index), its vector representation is changed to a matrix with dimensions 28x28.\n",
    "    \n",
    "    \n",
    "This is done by using the following function:\n",
    "    \n",
    "    plt.imshow(sets[0][index].reshape((28, 28)),cmap='gray')      #Images are in shades of gray\n",
    "\n",
    "Documentation: [matplotlib.pyplot.imshow(...)](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib-pyplot-imshow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.960465Z",
     "start_time": "2020-11-17T21:24:06.823984Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 1567\n",
    "\n",
    "plt.imshow(train_data[0][index].reshape((28, 28)),cmap='gray')\n",
    "\n",
    "print(train_data[1][index], \"is the digit corresponding to the sample\", index)\n",
    "print(\"\\n This is its image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Separation of the data into features (inputs) and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.965967Z",
     "start_time": "2020-11-17T21:24:06.962735Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_data[0]   # input (features) in the training data set\n",
    "y_train = train_data[1]   # target (the digit) in the training data set\n",
    "\n",
    "x_val = val_data[0]   # input (features) in the validation data set\n",
    "y_val = val_data[1]   # target (the digit) in the validation data set\n",
    "\n",
    "x_test = test_data[0]     # input (features) in the testing data set\n",
    "y_test = test_data[1]     # target (the digit) in the testing data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.979375Z",
     "start_time": "2020-11-17T21:24:06.968001Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(x_train))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.991634Z",
     "start_time": "2020-11-17T21:24:06.980745Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "One-hot encoding of target variable y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "The target value can have one of ten elements (classes), the digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9). \n",
    "\n",
    "\n",
    "\n",
    "The train_y and test_y sets are arrangements in which each entry contains a digit. Each digit is represented as a integer of 64 bits.\n",
    "    \n",
    "    \n",
    "We change this representation to a vectorial one following One-hot encoding \n",
    "[One-hot encoding](https://en.wikipedia.org/wiki/One-hot).\n",
    "    \n",
    "    \n",
    "In the One-Hot encoding, a digit is represented with a vector having dimension 10 (because we have 10 classes) with 1.0 in the vector index corresponding to the digit and 0.0 elsewhere in the vector. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue' >\n",
    "    \n",
    "Digit |     One-hot representation \n",
    "--- | --- \n",
    " 0  | [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " 1  | [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " 2  | [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    " 3  | [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    " 4  | [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    " 5  | [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    " 6  | [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " 7  | [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " 8  | [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
    " 9  | [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='purple'>\n",
    "Demo using numpy.eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.004858Z",
     "start_time": "2020-11-17T21:24:06.992874Z"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.016302Z",
     "start_time": "2020-11-17T21:24:07.006472Z"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.028455Z",
     "start_time": "2020-11-17T21:24:07.017626Z"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(10)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.040513Z",
     "start_time": "2020-11-17T21:24:07.029624Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T19:22:13.283991Z",
     "start_time": "2020-11-16T19:22:13.273520Z"
    }
   },
   "source": [
    "np.eye(10)[train_y[0:5].reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.054673Z",
     "start_time": "2020-11-17T21:24:07.041917Z"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(10)[y_train[0:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='purple'>\n",
    "End of demo using numpy.eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.068451Z",
     "start_time": "2020-11-17T21:24:07.056597Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y = np.eye(10)[y_train]\n",
    "\n",
    "val_y = np.eye(10)[y_val]\n",
    "\n",
    "test_y = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.078264Z",
     "start_time": "2020-11-17T21:24:07.070283Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Y: Digit representation for the first training sample \\n\", y_train[0])\n",
    "print(\"Y: One-hot representation for the first training sample \\n\",train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "For convenience, the dimensions of the input sets will be changed to the format:\n",
    "\n",
    "(number of samples, image width, image length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.090004Z",
     "start_time": "2020-11-17T21:24:07.079918Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = x_train.reshape(50000, 28, 28)\n",
    "val_x  = x_val.reshape(10000, 28, 28)\n",
    "test_x = x_test.reshape(10000, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "In summary, the following dimensions are used for the training and the test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.103786Z",
     "start_time": "2020-11-17T21:24:07.091277Z"
    }
   },
   "outputs": [],
   "source": [
    "print (\"number of training examples = \" + str(train_x.shape[0]))\n",
    "print (\"number of validation examples = \" + str(val_x.shape[0]))\n",
    "print (\"number of test examples = \" + str(test_x.shape[0]))\n",
    "\n",
    "print (\"train_x shape: \" + str(train_x.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "\n",
    "print (\"val_x shape: \" + str(val_x.shape))\n",
    "print (\"val_y shape: \" + str(val_y.shape))\n",
    "\n",
    "print (\"test_x shape: \" + str(test_x.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:05:44.199775Z",
     "start_time": "2020-03-24T17:05:44.190483Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Constructing the Learning System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:05:44.199775Z",
     "start_time": "2020-03-24T17:05:44.190483Z"
    }
   },
   "source": [
    "<font size=5 color=\"black\">\n",
    "\n",
    "Displaying the architecture of the desired neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.249974Z",
     "start_time": "2020-11-17T21:24:07.105436Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "class Network(object):\n",
    "    \n",
    "    def  __init__ (self,sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        print(\"It has\", self.num_layers, \"layers,\")\n",
    "        self.sizes = sizes\n",
    "        print(\"with the following number of nodes per layer\",self.sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedforward(self, x_of_sample):\n",
    "        \"\"\"Return the output of the network F(x_of_sample) \"\"\"        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            x_of_sample = sigmoid(np.dot(w, x_of_sample)+b)\n",
    "        return x_of_sample\n",
    "    \n",
    "    def graph(self,sizes):\n",
    "        a=[]\n",
    "        ps={}\n",
    "        Q = nx.Graph()\n",
    "        for i in range(len(sizes)):\n",
    "            Qi=nx.Graph()    \n",
    "            n=sizes[i]\n",
    "            nodos=np.arange(n)\n",
    "            Qi.add_nodes_from(nodos)\n",
    "            l_i=Qi.nodes\n",
    "            Q = nx.union(Q, Qi, rename = (None, 'Q%i-'%i))\n",
    "            if len(l_i)==1:\n",
    "                ps['Q%i-0'%i]=[i/(len(sizes)), 1/2]\n",
    "            else:\n",
    "                for j in range(len(l_i)+1):\n",
    "                    ps['Q%i-%i'%(i,j)]=[i/(len(sizes)),(1/(len(l_i)*len(l_i)))+(j/(len(l_i)))]\n",
    "            a.insert(i,Qi)\n",
    "        for i in range(len(a)-1):\n",
    "            for j in range(len(a[i])):\n",
    "                for k in range(len(a[i+1])):\n",
    "                    Q.add_edge('Q%i-%i' %(i,j),'Q%i-%i' %(i+1,k))\n",
    "        nx.draw(Q, pos = ps)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.844313Z",
     "start_time": "2020-11-17T21:24:07.251233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Architecture of the neural network we want to implement in the present notebook\n",
    "\n",
    "layers = [784,20,10]\n",
    "net = Network(layers)\n",
    "net.graph(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Definition of the neural network architecture\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='black'> \n",
    "    \n",
    "Keras has two different modes to define the architecture:\n",
    "\n",
    "<font size=4 color='black'> \n",
    "    \n",
    "1.- The sequential model. It is a sequential stack of layers.\n",
    "    \n",
    "2.- The functional API. It is the way to go for defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers.  \n",
    "\n",
    "In the present case, we will use this last mode for constructing the architecture of the network.\n",
    "    \n",
    "\n",
    "Documentation: [Keras Functional API](https://keras.io/getting-started/functional-api-guide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.852568Z",
     "start_time": "2020-11-17T21:24:07.845843Z"
    }
   },
   "outputs": [],
   "source": [
    "def architecture(input_shape, num_clases):Loop\n",
    "    \n",
    "    # Defining the input as a tensor with shape input_shape. \n",
    "    inputs = Input(input_shape, name='input-layer')\n",
    "    \n",
    "    # Flattening the input tensor of dimensions (28,28,1) to a tensor of dimensions (784, 1)\n",
    "    x = Flatten()(inputs)\n",
    "    \n",
    "    # Defining the first hidden layer with 20 nodes and sigmoid as activation function\n",
    "    x = Dense(20, kernel_initializer='uniform', bias_initializer='zeros', name='hidden-layer')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    # Defining the first hidden layer with num_clases nodes and softmax as activation funcion, which is\n",
    "    x = Dense(num_clases, kernel_initializer='uniform', bias_initializer='zeros')(x)\n",
    "    \n",
    "    # For the output layer we use the activation function 'softmax'\n",
    "    outputs = Activation('softmax', name='output.layer')(x)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.    \n",
    "    arch_model = Model(inputs = inputs, outputs = outputs, name='MnistModel')\n",
    "\n",
    "    return arch_model"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'> \n",
    "\n",
    "    \n",
    "   *The softmax activation function is always used for classification when the number (K) of classes is larger than two.* \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "    \n",
    "    \n",
    "    \n",
    "It is used to compute probability distribution from a vector of real numbers. \n",
    "\n",
    "The Softmax function produces an output which is a range of values between 0 and 1, with the sum of the probabilities been equal to 1. \n",
    "\n",
    "\n",
    "The Softmax function is used in multi-class models where it returns probabilities of each class, with the target class having\n",
    "the highest probability.\n",
    "\n",
    "\n",
    "[Activation functions](./clase8/activation_functions_2018.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T18:29:47.071906Z",
     "start_time": "2020-03-24T18:29:47.067719Z"
    }
   },
   "source": [
    "\n",
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Constructing the neural network model for the Learning System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.919154Z",
     "start_time": "2020-11-17T21:24:07.856354Z"
    }
   },
   "outputs": [],
   "source": [
    "one_image = (28,28)\n",
    "num_classes= 10\n",
    "\n",
    "# Generating a model using the architecture defined for the neural network\n",
    "mnist_model = architecture(one_image, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T00:03:50.539765Z",
     "start_time": "2020-03-24T00:03:50.534266Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "    \n",
    "Model plot and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'> \n",
    "The function 'plot_model()' generates a graphic with the layers and their number of input ands output weights.\n",
    "$$ $$\n",
    "Documentation: [Model visualization](https://keras.io/visualization/#training-history-visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.012027Z",
     "start_time": "2020-11-17T21:24:07.920779Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(mnist_model, to_file='FF_mnist_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.018904Z",
     "start_time": "2020-11-17T21:24:08.013470Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T22:54:01.482701Z",
     "start_time": "2020-11-15T22:54:01.471240Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "This requires defining the optimization algorithm, the loss function and the metric.\n",
    "    \n",
    "In the present case we are using the algorithm of Stochastic Gradient descent with learning rate \"lr\", \"momentum\" without Nesterov acceleration\".\n",
    "\n",
    "\n",
    "[An overview of gradient descent optimization algorithms](./clase8/SGD_overview_2016-17.pdf)\n",
    "\n",
    "This publication also comments some other optimization variants of this algorithm; Adagrad, Adadelta, RMStrop and Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T18:24:57.726929Z",
     "start_time": "2020-11-17T18:24:57.717602Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.045698Z",
     "start_time": "2020-11-17T21:24:08.020323Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T18:09:46.075549Z",
     "start_time": "2020-11-17T18:09:46.071063Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "The cost (loss) and Metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "The cost function *J* is the one defined as \"categorical_crossentropy\"\n",
    "    \n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=0}^{K-1}(y_k^{(i)}*\\log{(F_k(x^{(i)})))}$$\n",
    "    \n",
    " where $F_k(x^{(i)})$ is the predicted value and $y_k^{(i)}$ is the target value for the sample *i*; *K* is the number of classes and *m* is the number of samples.\n",
    "    \n",
    "[Cross entropy](https://en.wikipedia.org/wiki/Cross_entropy)\n",
    "\n",
    "Any loss consisting of a negative log-likelihood is a cross entropy between the empirical distribution defined by the training set and the model. For example, mean squared error is the cross-entropy between the empirical distribution and a Gaussian model.\n",
    "\n",
    "        Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning, pp 132\n",
    "\n",
    "    \n",
    "[Categorical cross entropy](https://www.deeplearningbook.org/)\n",
    "\n",
    "You can find more information about cross entropy in \n",
    "\n",
    "\n",
    "     Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. pp 913\n",
    "    \n",
    "\n",
    "A metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model. You may use any of the loss functions as a metric function. In the present example, we are using \"accuracy\" as metrics:\n",
    "    \n",
    "*Accuracy = Number of correct predictions / Total number of predictions made*\n",
    "    \n",
    "\n",
    "Categorical crossentropy will compare the distribution of the predictions (the activations in the output layer, one for each class) with the true distribution, where the probability of the true class is set to 1, and 0 for the other classes.\n",
    "\n",
    "To put it in a different way, the true class is represented as an encoded vector, and the closer the modelâ€™s outputs are to that vector, the lower the loss.\n",
    "    \n",
    "Documentation:\n",
    "\n",
    "[keras.compile(...)](https://keras.io/models/model/#compile)\n",
    "\n",
    "\n",
    "[Keras losses](https://keras.io/api/losses/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.049657Z",
     "start_time": "2020-11-17T21:24:08.047124Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = 'categorical_crossentropy'\n",
    "metric_function = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.108610Z",
     "start_time": "2020-11-17T21:24:08.051598Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_model.compile(optimizer = optimizer, loss = loss_function, metrics = [metric_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Training the learning system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "Documentation: [keras.fit(...)](https://keras.io/models/model/#fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:30.676613Z",
     "start_time": "2020-11-17T21:24:08.110028Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "history = mnist_model.fit(x = train_x, y = train_y, epochs=num_epochs, batch_size = 100, \\\n",
    "                          validation_data=(val_x,val_y), shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "* Note: if you run `fit()` again, the `model` will continue training, starting with the parameters it has already learnt, instead of reinitializing them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Plotting the cost function of training and validation data sets as a function of the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:30.833216Z",
     "start_time": "2020-11-17T21:25:30.678097Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Cost function')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "Plotting the accuracy function of training and validation sets as a function of the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:30.956998Z",
     "start_time": "2020-11-17T21:25:30.834617Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='blue'>\n",
    "\n",
    "Loss and accuracy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= 4 color='black'>    \n",
    "After training the network, the loss and accuracy functions are evaluated using the test samples (test_x, test_y). This is done using the Keras Method evaluate(x=None, y=None, ...).\n",
    "    \n",
    "\n",
    "    \n",
    "[Method evaluate in Keras](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.307565Z",
     "start_time": "2020-11-17T21:25:30.959211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation using all the samples of the test set\n",
    "evaluations = mnist_model.evaluate(x = test_x, y = test_y)\n",
    "\n",
    "print (\"Loss = \" + str(evaluations[0]))\n",
    "print (\"Test Accuracy = \" + str(evaluations[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.318940Z",
     "start_time": "2020-11-17T21:25:31.308874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation using the first 100 samples of the test set\n",
    "\n",
    "evaluations = mnist_model.evaluate(x = test_x[:100], y = test_y[:100])\n",
    "\n",
    "print (\"Loss = \" + str(evaluations[0]))\n",
    "print (\"Test Accuracy = \" + str(evaluations[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='blue'>\n",
    "Digits prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= 4 color='black'>    \n",
    "The trained network can be used to generate predictions of the digists associated to new samples. For example, those in the test data (test_x, test_y). This is done using the Keras Method \"predict(x, ...)\"\n",
    "      \n",
    "[Method predict in Keras](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.525053Z",
     "start_time": "2020-11-17T21:25:31.320209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting the digits associated to each sample in the test set (test_x)\n",
    "predictions = mnist_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.529800Z",
     "start_time": "2020-11-17T21:25:31.526287Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = 2345\n",
    "\n",
    "# Predicting the digit associated to the sample \n",
    "# np.argmax returns the index of the maximum value\n",
    "\n",
    "prediction = np.argmax(predictions[sample])\n",
    "\n",
    "print('For the sample number', sample, 'the prediction is the digit:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\"> \n",
    "Displaying the digit associated (not predicted!) to this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.638216Z",
     "start_time": "2020-11-17T21:25:31.531127Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_data[0][sample].reshape((28, 28)), cmap='gray')\n",
    "\n",
    "print ('For the sample number', sample, 'the associated digit is:', np.squeeze(test_data[1][sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
