{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "   \n",
    "# Método de Newton-Rapshon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "El método de Newton-Rapshon se usa para encontrar las raíces de una función real. \n",
    "\n",
    "Se parte de la derivada de la función $f$ y una suposición inicial $x_0$ para una raíz de $f$. Si la función satisface suposiciones suficientes y la suposición inicial es cercana, entonces se mejora la aproximación de la raíz con:\n",
    "\n",
    "$$ x_1 = x_0 - \\dfrac{f(x_0)}{f´(x_0)}$$\n",
    "\n",
    "$(x_1, 0)$ es la intersección del eje $x$ y la tangente de la gráfica de $f$ en $(x_0, f(x_0))$.\n",
    "\n",
    "[Newton´s method](https://en.wikipedia.org/wiki/Newton%27s_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/NewtonIteration_Ani.gif\">\n",
    "\n",
    "(By Ralf Pfeifer - de:Image:NewtonIteration Ani.gif, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=2268473)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =4>\n",
    "\n",
    "Si el método se aplica a la derivada de una funcion $f$, es decir, se aplica a $f'$, entonces se pueden hallar los mínimos o máximos de $f$. \n",
    "\n",
    "[Newton´s method in optimization](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization#Newton's_Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:23:48.512206Z",
     "start_time": "2020-02-19T19:23:48.505586Z"
    }
   },
   "outputs": [],
   "source": [
    "def newton(f,Df,x0,epsilon,max_iter):\n",
    "    '''Approximate solution of f(x)=0 by Newton's method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        \n",
    "    Df : Derivative of f(x).\n",
    "    \n",
    "    x0 : Initial guess for a solution f(x)=0.\n",
    "    \n",
    "    epsilon :Stopping criteria is abs(f(x)) < epsilon.\n",
    "    \n",
    "    max_iter : Maximum number of iterations of Newton's method.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xn : number\n",
    "        Implement Newton's method: compute the linear approximation\n",
    "        of f(x) at xn and find x intercept by the formula\n",
    "            x = xn - f(xn)/Df(xn)\n",
    "        Continue until abs(f(xn)) < epsilon and return xn.\n",
    "        If Df(xn) == 0, return None. If the number of iterations\n",
    "        exceeds max_iter, then return None.\n",
    "    '''\n",
    "    \n",
    "    aprox_root = [x0]\n",
    "    \n",
    "    xn = x0\n",
    "      \n",
    "    # xn es la aproximación de la raíz de f. Inicialmente xn =x0 con x0 la primera aproximación\n",
    "    \n",
    "    for n in range(0,max_iter):\n",
    "        \n",
    "        fxn = f(xn)\n",
    "        \n",
    "        if abs(fxn) < epsilon:\n",
    "            \n",
    "            print('Found solution after',n,'iterations.')\n",
    "            \n",
    "            return xn, aprox_root\n",
    "        \n",
    "        Dfxn = Df(xn)\n",
    "        \n",
    "        if Dfxn == 0:\n",
    "            \n",
    "            print('Zero derivative. No solution found.')\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        xn = xn - fxn/Dfxn\n",
    "        \n",
    "        aprox_root.append(xn)\n",
    "        \n",
    "    print('Exceeded maximum iterations. No solution found.')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " Se define una función $p(x)=(x-1)^²-1$ y su derivada $Dp(x)=2(x-1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:23:50.698812Z",
     "start_time": "2020-02-19T19:23:50.684186Z"
    }
   },
   "outputs": [],
   "source": [
    "p = lambda x: (x-1)**2 - 1\n",
    "Dp = lambda x: 2*(x-1)\n",
    "\n",
    "newton(p, Dp,10,1e-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:23:54.710247Z",
     "start_time": "2020-02-19T19:23:54.702935Z"
    }
   },
   "outputs": [],
   "source": [
    " def tangent_line(f,Df, x_0,a,b):\n",
    "    x = np.linspace(a,b)\n",
    "    y = f(x) \n",
    "    y_0 = f(x_0)\n",
    "    y_tan = Dp(x_0) * (x - x_0) + y_0 \n",
    "   \n",
    "  #plotting\n",
    "    plt.plot(x,y,'r-')\n",
    "    plt.plot(x,y_tan,'b-')\n",
    "    plt.axis([a,b,a,b])\n",
    "    plt.xlabel('x')     \n",
    "    plt.ylabel('y')  \n",
    "    plt.grid(True)\n",
    "    plt.title('Plot of a function with tangent line') \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:23:57.008856Z",
     "start_time": "2020-02-19T19:23:55.689012Z"
    }
   },
   "outputs": [],
   "source": [
    "p = lambda x: (x-1)**2 - 1\n",
    "Dp = lambda x: 2*(x-1)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in newton(p, Dp,13,1e-10,10)[1]:\n",
    "    print(i)\n",
    "    tangent_line(p, Dp, i, -5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Es un algoritmo de optimizacion para encontrar el mínimo local de una función diferenciable.\n",
    "\n",
    "Para encontrar un mínimo local de una función usando el descenso de gradiente, se toman pasos proporcionales al negativo del gradiente (o gradiente aproximado) de la función en el punto actual.\n",
    "\n",
    "[Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:23:58.724364Z",
     "start_time": "2020-02-19T19:23:58.578709Z"
    }
   },
   "outputs": [],
   "source": [
    "f = lambda x: x**3 - 3*x**2 + 7\n",
    "x = np.linspace(-1,3,500)\n",
    "plt.plot(x, f(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:23:59.698226Z",
     "start_time": "2020-02-19T19:23:59.538095Z"
    }
   },
   "outputs": [],
   "source": [
    "df = lambda x: 3*x**2 - 6*x\n",
    "x = np.linspace(-1,3,500)\n",
    "plt.plot(x, df(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:24:00.389378Z",
     "start_time": "2020-02-19T19:24:00.371203Z"
    }
   },
   "outputs": [],
   "source": [
    "next_x = 6  # We start the search at x=6\n",
    "gamma = 0.01  # Step size multiplier\n",
    "precision = 0.00001  # Desired precision of result\n",
    "max_iters = 10000  # Maximum number of iterations\n",
    "\n",
    "\n",
    "xs = [next_x]\n",
    "\n",
    "for _i in range(max_iters):\n",
    "    \n",
    "    current_x = next_x\n",
    "    \n",
    "    next_x = current_x - gamma * df(current_x)\n",
    "    \n",
    "    xs.append(next_x)\n",
    "\n",
    "    step = next_x - current_x\n",
    "    \n",
    "    if abs(step) <= precision:\n",
    "        \n",
    "        break\n",
    "        \n",
    "print(\"Minimum at {0:5.2f}\".format(next_x))\n",
    "\n",
    "# The output for the above will be something like\n",
    "# \"Minimum at 2.2499646074278457\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:24:01.597874Z",
     "start_time": "2020-02-19T19:24:01.476433Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x, f(x), 'red')\n",
    "xs = np.asarray(xs[4:17])\n",
    "plt.scatter(xs, f(xs))\n",
    "#plt.xlim([0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Implement Gradient Descent in Python: towards data science](https://towardsdatascience.com/implement-gradient-descent-in-python-9b93ed7108d1)\n",
    "\n",
    "[Implementation of Gradient Descent in Python: medium](https://medium.com/coinmonks/implementation-of-gradient-descent-in-python-a43f160ec521)\n",
    "\n",
    "[Linear Regression using Gradient Descent](https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931)\n",
    "\n",
    "[Video Ng](https://www.youtube.com/watch?v=TuttBDdbls8&t=122s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Ejemplo\n",
    "\n",
    "## Ajuste de un pico de difracción de rayos X con una Gaussiana usando el metodo de Newton-Rapshon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:24:04.629551Z",
     "start_time": "2020-02-19T19:24:04.617153Z"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "fopen = open('diffraction-pattern.xy')\n",
    "\n",
    "fread = fopen.readlines()\n",
    "\n",
    "for j in range(len(fread)):\n",
    "    \n",
    "    sample = fread[j].split()\n",
    "\n",
    "    X.append(float(sample[0]))\n",
    "    Y.append(float(sample[1]))\n",
    "\n",
    "X_array = np.asarray(X)\n",
    "Y_array = np.asarray(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:24:05.894697Z",
     "start_time": "2020-02-19T19:24:05.725519Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(13,8))\n",
    "\n",
    "plt.plot(X_array, Y_array, color='red', markersize=3)\n",
    "plt.ylabel('intensity', fontsize=16)\n",
    "plt.xlabel('2*theta', fontsize=16)\n",
    "\n",
    "plt.title('X-ray Diffraction Pattern', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:24:05.894697Z",
     "start_time": "2020-02-19T19:24:05.725519Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_ = X_array[530:730]\n",
    "y_ = Y_array[530:730]\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "\n",
    "plt.rc('xtick', labelsize=14)\n",
    "plt.rc('ytick', labelsize=14)\n",
    "plt.rc('legend', fontsize=16)\n",
    "\n",
    "plt.plot(x_, y_, '.', color='red', markersize=6)\n",
    "plt.ylabel('intensity', fontsize=16)\n",
    "plt.xlabel('2*theta', fontsize=16)\n",
    " \n",
    "plt.title('XRDP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Ajustando a los datos una curva Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:24:07.260804Z",
     "start_time": "2020-02-19T19:24:07.060166Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "\n",
    "# weighted arithmetic mean (corrected - check the section below)\n",
    "mean = sum(x_ * y_) / sum(y_)\n",
    "sigma = np.sqrt(sum(y_ * (x_ - mean)**2) / sum(y_))\n",
    "\n",
    "def Gauss(x_, a, x0, sigma):\n",
    "    return a * np.exp(-(x_ - x0)**2 / (2 * sigma**2))\n",
    "\n",
    "popt,pcov = curve_fit(Gauss, x_, y_, p0=[max(y_), mean, sigma])\n",
    "\n",
    "print(popt)\n",
    "print(pcov)\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(x_, y_, 'b+:', label='data')\n",
    "plt.plot(x_, Gauss(x_, *popt), 'r-', label='fit')\n",
    "plt.ylabel('intensity', fontsize=16)\n",
    "plt.xlabel('2*theta', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Ajustando a los datos una curva Lorentziana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T19:24:07.260804Z",
     "start_time": "2020-02-19T19:24:07.060166Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "\n",
    "# weighted arithmetic mean (corrected - check the section below)\n",
    "mean = sum(x_ * y_) / sum(y_)\n",
    "sigma = np.sqrt(sum(y_ * (x_ - mean)**2) / sum(y_))\n",
    "\n",
    "def Lorentzian(x_, a, x0, sigma):\n",
    "    \n",
    "    return (a /3.14159 ) * ((sigma/2) / ((x_-x0)**2 + (sigma/2)**2))\n",
    "\n",
    "popt,pcov = curve_fit(Lorentzian, x_, y_, p0=[max(y_), mean, sigma])\n",
    "\n",
    "print(popt)\n",
    "print(pcov)\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(x_, y_, 'b+:', label='data')\n",
    "plt.plot(x_, Lorentzian(x_, *popt), 'r-', label='fit')\n",
    "plt.ylabel('intensity', fontsize=16)\n",
    "plt.xlabel('2*theta', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[from scipy.optimize import curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html)\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
